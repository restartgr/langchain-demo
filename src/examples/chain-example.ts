import { ChatOpenAI } from "@langchain/openai";
import { PromptTemplate } from "@langchain/core/prompts";
import { LLMChain } from "langchain/chains";
import { SequentialChain } from "langchain/chains";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";
import { config } from "../config/index.js";

export async function chainExample(): Promise<void> {
  console.log("â›“ï¸ é“¾å¼è°ƒç”¨æ¼”ç¤ºå¼€å§‹...");

  try {
    // åˆå§‹åŒ–èŠå¤©æ¨¡å‹
    const llm = new ChatOpenAI({
      openAIApiKey: config.openai.apiKey!,
      modelName: config.models.chat,
      temperature: config.app.temperature,
      maxTokens: config.app.maxTokens,
    });

    console.log("\n1. ç®€å•LLMé“¾æ¼”ç¤º");
    console.log("â”€".repeat(30));

    // åˆ›å»ºæç¤ºæ¨¡æ¿
    const promptTemplate = PromptTemplate.fromTemplate(`
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆ{target_language}ï¼Œå¹¶ä¿æŒåŸæ„ä¸å˜ï¼š

åŸæ–‡ï¼š{text}

ç¿»è¯‘ï¼š`);

    // åˆ›å»ºLLMé“¾
    const translateChain = new LLMChain({
      llm,
      prompt: promptTemplate,
      outputKey: "translation",
    });

    // æµ‹è¯•ç¿»è¯‘é“¾
    const translationResult = await translateChain.call({
      text: "LangChain is a framework for developing applications powered by language models.",
      target_language: "ä¸­æ–‡",
    });

    console.log("ğŸ”¤ ç¿»è¯‘ç»“æœ:", translationResult.translation);

    console.log("\n2. é¡ºåºé“¾æ¼”ç¤º");
    console.log("â”€".repeat(30));

    // åˆ›å»ºç¬¬ä¸€ä¸ªé“¾ï¼šç”Ÿæˆæ•…äº‹å¤§çº²
    const outlinePrompt = PromptTemplate.fromTemplate(`
è¯·æ ¹æ®ä»¥ä¸‹ä¸»é¢˜åˆ›å»ºä¸€ä¸ªç®€çŸ­çš„æ•…äº‹å¤§çº²ï¼š

ä¸»é¢˜ï¼š{topic}

æ•…äº‹å¤§çº²ï¼š`);

    const outlineChain = new LLMChain({
      llm,
      prompt: outlinePrompt,
      outputKey: "outline",
    });

    // åˆ›å»ºç¬¬äºŒä¸ªé“¾ï¼šæ‰©å±•æ•…äº‹
    const storyPrompt = PromptTemplate.fromTemplate(`
åŸºäºä»¥ä¸‹æ•…äº‹å¤§çº²ï¼Œå†™ä¸€ä¸ªè¯¦ç»†çš„çŸ­æ•…äº‹ï¼ˆ200å­—å·¦å³ï¼‰ï¼š

å¤§çº²ï¼š{outline}

æ•…äº‹ï¼š`);

    const storyChain = new LLMChain({
      llm,
      prompt: storyPrompt,
      outputKey: "story",
    });

    // åˆ›å»ºç¬¬ä¸‰ä¸ªé“¾ï¼šæ€»ç»“æ•…äº‹
    const summaryPrompt = PromptTemplate.fromTemplate(`
è¯·ä¸ºä»¥ä¸‹æ•…äº‹å†™ä¸€ä¸ªç®€çŸ­çš„æ€»ç»“ï¼ˆ50å­—ä»¥å†…ï¼‰ï¼š

æ•…äº‹ï¼š{story}

æ€»ç»“ï¼š`);

    const summaryChain = new LLMChain({
      llm,
      prompt: summaryPrompt,
      outputKey: "summary",
    });

    // åˆ›å»ºé¡ºåºé“¾
    const sequentialChain = new SequentialChain({
      chains: [outlineChain, storyChain, summaryChain],
      inputVariables: ["topic"],
      outputVariables: ["outline", "story", "summary"],
      verbose: true,
    });

    console.log("ğŸ“ å¼€å§‹åˆ›ä½œæ•…äº‹...");
    const storyResult = await sequentialChain.call({
      topic: "ä¸€åªä¼šè¯´è¯çš„çŒ«å’ªå’Œå®ƒçš„å†’é™©",
    });

    console.log("\nğŸ“– åˆ›ä½œç»“æœ:");
    console.log("â”€".repeat(20));
    console.log("ğŸ’¡ æ•…äº‹å¤§çº²:", storyResult.outline.trim());
    console.log("\nğŸ“š å®Œæ•´æ•…äº‹:", storyResult.story.trim());
    console.log("\nğŸ“‹ æ•…äº‹æ€»ç»“:", storyResult.summary.trim());

    console.log("\n3. æ¡ä»¶é“¾æ¼”ç¤º");
    console.log("â”€".repeat(30));

    // æ¼”ç¤ºæ¡ä»¶æ€§çš„é“¾è°ƒç”¨
    const analyzeAndRespond = async (userInput: string): Promise<void> => {
      console.log(`ğŸ” åˆ†æç”¨æˆ·è¾“å…¥: "${userInput}"`);

      // ç¬¬ä¸€æ­¥ï¼šåˆ†æè¾“å…¥ç±»å‹
      const analysisPrompt = PromptTemplate.fromTemplate(`
è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥å±äºä»€ä¹ˆç±»å‹ï¼Œåªå›ç­”ç±»å‹åç§°ï¼ˆé—®é¢˜ã€è¯·æ±‚ã€æŠ±æ€¨ã€èµç¾ã€å…¶ä»–ï¼‰ï¼š

ç”¨æˆ·è¾“å…¥ï¼š{input}

ç±»å‹ï¼š`);

      const analysisChain = new LLMChain({
        llm,
        prompt: analysisPrompt,
      });

      const analysisResult = await analysisChain.call({ input: userInput });
      const inputType = analysisResult.text.trim();

      console.log(`ğŸ“Š è¾“å…¥ç±»å‹: ${inputType}`);

      // æ ¹æ®ç±»å‹é€‰æ‹©ä¸åŒçš„å“åº”ç­–ç•¥
      let responsePrompt: PromptTemplate;

      if (inputType.includes("é—®é¢˜")) {
        responsePrompt = PromptTemplate.fromTemplate(`
ç”¨æˆ·é—®äº†ä¸€ä¸ªé—®é¢˜ï¼Œè¯·æä¾›æœ‰å¸®åŠ©çš„ç­”æ¡ˆï¼š

é—®é¢˜ï¼š{input}

ç­”æ¡ˆï¼š`);
      } else if (inputType.includes("æŠ±æ€¨")) {
        responsePrompt = PromptTemplate.fromTemplate(`
ç”¨æˆ·è¡¨è¾¾äº†æŠ±æ€¨ï¼Œè¯·ä»¥åŒç†å¿ƒå›åº”å¹¶æä¾›å»ºè®¾æ€§å»ºè®®ï¼š

æŠ±æ€¨ï¼š{input}

å›åº”ï¼š`);
      } else if (inputType.includes("èµç¾")) {
        responsePrompt = PromptTemplate.fromTemplate(`
ç”¨æˆ·è¡¨è¾¾äº†èµç¾ï¼Œè¯·ç¤¼è²Œåœ°è¡¨ç¤ºæ„Ÿè°¢ï¼š

èµç¾ï¼š{input}

å›åº”ï¼š`);
      } else {
        responsePrompt = PromptTemplate.fromTemplate(`
è¯·å¯¹ç”¨æˆ·çš„è¾“å…¥ç»™å‡ºåˆé€‚çš„å›åº”ï¼š

è¾“å…¥ï¼š{input}

å›åº”ï¼š`);
      }

      const responseChain = new LLMChain({
        llm,
        prompt: responsePrompt,
      });

      const response = await responseChain.call({ input: userInput });
      console.log(`ğŸ’¬ AIå›åº”: ${response.text.trim()}`);
    };

    // æµ‹è¯•ä¸åŒç±»å‹çš„è¾“å…¥
    const testInputs = [
      "LangChainæ˜¯ä»€ä¹ˆï¼Ÿ",
      "è¿™ä¸ªè½¯ä»¶å¤ªéš¾ç”¨äº†ï¼",
      "è¿™ä¸ªæ¼”ç¤ºåšå¾—çœŸä¸é”™ï¼",
      "ä»Šå¤©å¤©æ°”çœŸå¥½ã€‚",
    ];

    for (const input of testInputs) {
      await analyzeAndRespond(input);
      console.log("");
    }
  } catch (error) {
    console.error(
      "âŒ é“¾å¼è°ƒç”¨æ¼”ç¤ºå‡ºé”™:",
      error instanceof Error ? error.message : String(error)
    );
  }
}

// å…è®¸å•ç‹¬è¿è¡Œæ­¤æ–‡ä»¶
if (import.meta.url === `file://${process.argv[1]}`) {
  chainExample();
}
